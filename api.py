from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional
from services import chat_service
import os
import logging
import httpx
from openai import OpenAI
from config import settings
from skills.loader import skill_loader
from skills.matcher import skill_matcher
from skills.base import SkillContext, SkillResult

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(pathname)s:%(lineno)d - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/chat", tags=["chat"])


# é…ç½®ä»£ç†ï¼ˆæ ¹æ®ä½ çš„å®é™…ä»£ç†åœ°å€ä¿®æ”¹ï¼‰
proxies = {
    "https://": "https://api.deepseek.com",
}

# åˆ›å»ºå¸¦ä»£ç†çš„ httpx å®¢æˆ·ç«¯
http_client = httpx.Client(timeout=30.0)
client = OpenAI(
    api_key=settings.OPENAI_API_KEY,
    base_url=settings.OPENAI_BASE_URL,
    http_client=http_client)  



class Message(BaseModel):
    role: str  # "user", "assistant", "system"
    content: str


class ChatRequest(BaseModel):
    messages: List[Message]
    model: Optional[str] = None
    stream: bool = False
    enable_skills: bool = True


@router.get("/skills")
async def list_skills():
    """è·å–æ‰€æœ‰å¯ç”¨çš„ Skills"""
    skills = skill_loader.list_skills()
    return {
        "total": len(skills),
        "skills": [
            {
                "name": skill.name,
                "description": skill.description,
                "category": skill.category,
                "tags": skill.tags or [],
                "author": skill.author,
                "version": skill.version
            }
            for skill in skills
        ]
    }


@router.post("/skills/reload")
async def reload_skills():
    """é‡æ–°åŠ è½½æ‰€æœ‰ Skills"""
    skill_loader.reload()
    return {"message": "Skills reloaded successfully"}


@router.get("/skills/{skill_name}")
async def get_skill_detail(skill_name: str):
    """è·å–æŒ‡å®š Skill çš„è¯¦ç»†ä¿¡æ¯"""
    skill = skill_loader.get_skill(skill_name)
    if not skill:
        raise HTTPException(status_code=404, detail=f"Skill '{skill_name}' not found")
    
    return {
        "metadata": skill.metadata.model_dump(),
        "references": list(skill.references.keys())
    }


@router.post("/")
async def chat(request: ChatRequest):
    """èŠå¤©æ¥å£ - æ”¯æŒè‡ªåŠ¨ Skills è°ƒç”¨"""
    messages = [{"role": msg.role, "content": msg.content} for msg in request.messages]

    # è·å–ç”¨æˆ·æœ€æ–°æ¶ˆæ¯
    user_message = messages[-1]["content"] if messages else ""

    logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚ - enable_skills={request.enable_skills}, user_message='{user_message}'")

    # åˆ›å»ºå¼‚æ­¥ç”Ÿæˆå™¨
    async def generate():
        # æ­¥éª¤1: å¦‚æœå¯ç”¨äº† Skillsï¼Œå°è¯•åŒ¹é… Skill
        if request.enable_skills and user_message.strip():
            logger.info("å¼€å§‹åŒ¹é… Skill...")
            yield "ğŸ” åˆ†æè¯·æ±‚...\n"

            matched = skill_matcher.match_skill(
                user_message,
                messages[:-1]
            )

            if matched:
                skill, confidence = matched
                logger.info(f"âœ… åŒ¹é…åˆ° Skill: {skill.metadata.name}, ç½®ä¿¡åº¦: {confidence:.2%}")
                yield f"âœ… æ‰¾åˆ°åˆé€‚çš„ Skill: {skill.metadata.name} (ç½®ä¿¡åº¦: {confidence:.2%})\n\n"

                # æ‰§è¡Œ Skill
                logger.info(f"ğŸ“ æ­£åœ¨æ‰§è¡Œ Skill: {skill.metadata.name}")
                yield f"ğŸ“ æ­£åœ¨æ‰§è¡Œ Skill: {skill.metadata.name}...\n"

                context = SkillContext(
                    user_message=user_message,
                    conversation_history=messages
                )

                result: SkillResult = await skill.execute(context)

                logger.info(f"Skill æ‰§è¡Œç»“æœ - success={result.success}, error={result.error}")

                if result.success:
                    logger.info(f"âœ… Skill æ‰§è¡ŒæˆåŠŸ, å†…å®¹é•¿åº¦: {len(result.content)}")
                    yield f"âœ… æ‰§è¡ŒæˆåŠŸ:\n\n{result.content}\n"
                else:
                    logger.error(f"âŒ Skill æ‰§è¡Œå¤±è´¥: {result.error}")
                    yield f"âŒ æ‰§è¡Œå¤±è´¥: {result.error}\n"

                # æ›´æ–°å¯¹è¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": f"ä½¿ç”¨äº† {skill.metadata.name} Skill"
                })

                logger.info("Skill æ‰§è¡Œå®Œæˆï¼Œè¿”å›ç»“æœ")
                return  # Skill æ‰§è¡Œå®Œæˆï¼Œä¸å†è°ƒç”¨æ™®é€šèŠå¤©
            else:
                logger.info("æœªåŒ¹é…åˆ°ä»»ä½• Skillï¼Œç»§ç»­æ™®é€šèŠå¤©")
        else:
            if not request.enable_skills:
                logger.info("Skills åŠŸèƒ½æœªå¯ç”¨ï¼Œä½¿ç”¨æ™®é€šèŠå¤©")
            if not user_message.strip():
                logger.info("ç”¨æˆ·æ¶ˆæ¯ä¸ºç©ºï¼Œè·³è¿‡ Skill åŒ¹é…")

        # æ­¥éª¤2: æ™®é€š AI èŠå¤©ï¼ˆæ²¡æœ‰åŒ¹é…åˆ° Skill æˆ–æœªå¯ç”¨ Skillsï¼‰
        logger.info("ğŸ’­ å¼€å§‹æ™®é€š AI èŠå¤©...")
        yield "ğŸ’­ æ­£åœ¨æ€è€ƒ...\n"

        stream = client.chat.completions.create(
            model=request.model or "deepseek-chat",
            messages=messages,
            stream=True
        )

        for chunk in stream:
            if chunk.choices[0].delta.content:
                yield chunk.choices[0].delta.content

        logger.info("æ™®é€š AI èŠå¤©å®Œæˆ")

    return StreamingResponse(generate(), media_type="text/plain")
